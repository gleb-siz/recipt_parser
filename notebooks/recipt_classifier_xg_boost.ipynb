{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5522b8ca",
   "metadata": {},
   "source": [
    "## Parse the total sum from recipt OCR data using xgboost classifier\n",
    "XGBoost model is trained using SROIE2019 Dataset\n",
    "Implemented as a binary classifier of tokens detected by OCR (Paddle OCR) pipeline to reprepsent total amount by recpit (1) or not (0)\n",
    "Model rely on spatial features derived from bbox: coordinates, continous and discrete representation of coordinates (row/column) in recipt, relative features (is the same row as \"TOTAL\" token), and textual features: is token a digit, digit value etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98588332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f78a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "# data load\n",
    "TRAIN_FOLDER = \"/home/gleb_siz/ml_training/data/SROIE2019/train\"\n",
    "TEST_FOLDER = \"/home/gleb_siz/ml_training/data/SROIE2019/test\"\n",
    "FEATURES = [\n",
    "## file level\n",
    "    \"file_aspect_ratio\",\n",
    "    \"x_max\",\n",
    "    \"token_width\",\n",
    "    \"token_heigh\",\n",
    "    \"aspect_ratio\",\n",
    "    \"row\",\n",
    "    \"col\",\n",
    "    \"row_rank\",\n",
    "    \"col_rank\",\n",
    "    \"has_total_keyword_in_row\",\n",
    "    \"tokens_in_col\",\n",
    "    \"tokens_in_row\",\n",
    "    \"text_length\",\n",
    "    \"is_digit\",\n",
    "    'font_size',\n",
    "    'row_dist_from_total',\n",
    "    \"value\",\n",
    "    \"rows_in_col\",\n",
    "    \"cols_in_row\",\n",
    "    \"has_total_below\",\n",
    "\n",
    "    # \"n_tokens\",\n",
    "    # \"width\",\n",
    "    # \"heigh\",\n",
    "    # \"tokens_top\",\n",
    "    # \"tokens_bottom\",\n",
    "    # \"tokens_left\",\n",
    "    # \"tokens_right\",  \n",
    "    # \"y_max\",\n",
    "    # \"section\",\n",
    "    # \"section_rank\",\n",
    "    # \"tokens_in_section\",\n",
    "    ]\n",
    "\n",
    "total_keywords = [\n",
    "    \"total\", \n",
    "    # \"amount\", \n",
    "    \"sum\", \n",
    "    \"suma\", \n",
    "    \"suma pln\",\n",
    "    \"sprzedaz\",\n",
    "    # \"subtotal\", \n",
    "    # \"balance\", \n",
    "    # \"due\", \n",
    "    # \"payment\", \n",
    "    # \"payable\", \n",
    "    # \"importe\", \n",
    "    # \"together\", \n",
    "    # \"totale\"\n",
    "]\n",
    "pattern = re.compile(r'\\b(' + '|'.join(total_keywords) + r')\\b', re.IGNORECASE)\n",
    "PRICE_PATTERN = re.compile(\n",
    "    r'^[A-Za-z $€¥£]*[:=]?\\s*\\$?\\s*[RM]*[+-]?([\\d]*[\\d.,]+)[ RMDHS]*$'\n",
    ")\n",
    "# Combined regex for numeric and short textual dates\n",
    "date_pattern = re.compile(\n",
    "    r'('\n",
    "    r'\\b\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2}\\b|'        # YYYY-MM-DD or YYYY/MM/DD\n",
    "    r'\\b\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4}\\b|'      # DD/MM/YYYY or DD.MM.YY\n",
    "    r'\\b\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|'\n",
    "    r'January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{2,4}\\b'\n",
    "    r')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "\n",
    "def match_price(text):\n",
    "    match = re.search(PRICE_PATTERN, text)\n",
    "    if not match:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def extract_price(text):\n",
    "    match = re.search(PRICE_PATTERN, text)\n",
    "    if not match:\n",
    "        return None\n",
    "    num = match.group(1).replace(',', '.')        # normalize commas\n",
    "    parts = num.split('.')                        # split by dot\n",
    "    if len(parts) == 1:\n",
    "        return float(parts[0])                    # just a plain integer\n",
    "    integer_part = ''.join(parts[:-1])            # join everything except last\n",
    "    decimal_part = parts[-1]\n",
    "    try:\n",
    "        return float(f\"{integer_part}.{decimal_part}\")\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_ocr(path):\n",
    "    ocr_output_df = pd.DataFrame()\n",
    "    for f in os.listdir(f\"{path}/box\"):\n",
    "        file = f\"{path}/box/{f}\"\n",
    "        with open(file) as fl:\n",
    "            try:\n",
    "                lines = fl.readlines()\n",
    "                df = pd.DataFrame(lines, columns=['raw'])\n",
    "                df['file'] = f\n",
    "                ocr_output_df = pd.concat([ocr_output_df, df])\n",
    "            except Exception as e:\n",
    "                print(\"Failed to process:\", file)\n",
    "    ocr_output_df[['x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4']] = ocr_output_df.apply(lambda x: pd.Series(x['raw'].split(',')[:8]), axis=1)\n",
    "    ocr_output_df['text'] = ocr_output_df.apply(lambda x: ','.join(x['raw'].split(',')[8:]).replace('\\n', ''), axis=1)\n",
    "    ocr_output_df['file'] = ocr_output_df['file'].apply(lambda x: x.split('.')[0])\n",
    "    ocr_output_df = ocr_output_df.replace('\\n', '')\n",
    "    ocr_output_df = ocr_output_df.dropna()\n",
    "    for col in ['x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4']:\n",
    "        ocr_output_df[col] = ocr_output_df[col].astype(int)\n",
    "    ocr_output_df['x_max'] = ocr_output_df.apply(lambda x: max(x['x1'], x['x2'], x['x3'], x['x4']), axis=1)\n",
    "    ocr_output_df['y_max'] = ocr_output_df.apply(lambda x: max(x['y1'], x['y2'], x['y3'], x['y4']), axis=1)\n",
    "    ocr_output_df['x_min'] = ocr_output_df.apply(lambda x: min(x['x1'], x['x2'], x['x3'], x['x4']), axis=1)\n",
    "    ocr_output_df['y_min'] = ocr_output_df.apply(lambda x: min(x['y1'], x['y2'], x['y3'], x['y4']), axis=1)\n",
    "    return ocr_output_df\n",
    "\n",
    "\n",
    "def load_img_data(path):\n",
    "    img_data = []\n",
    "    for f in os.listdir(f\"{path}/img\"):\n",
    "        file = f\"{path}/img/{f}\"\n",
    "        img = cv2.imread(file)\n",
    "        heigh, width, _ = img.shape\n",
    "        img_data.append((f, width, heigh))\n",
    "    img_df = pd.DataFrame(img_data, columns=['file', 'width', 'heigh'])\n",
    "    img_df['file'] = img_df['file'].apply(lambda x: x.split('.')[0])\n",
    "    return img_df\n",
    "\n",
    "\n",
    "def load_entity_data(path):\n",
    "    labels_df = pd.DataFrame()\n",
    "    labels = []\n",
    "    for f in os.listdir(f\"{path}/entities\"):\n",
    "        file = f\"{path}/entities/{f}\"\n",
    "        with open(file) as fl:\n",
    "            item = json.loads(fl.read())\n",
    "            for k, v in item.items():\n",
    "                labels.append({'label': k, 'text': v, 'file': f.split('.')[0]})\n",
    "            labels_df = pd.DataFrame(labels)\n",
    "    return labels_df\n",
    "\n",
    "def match_labels(train, labels):\n",
    "    matched_labels = []\n",
    "\n",
    "    for _, row in train.iterrows():\n",
    "        file = row['file']\n",
    "        text = str(row['text'])\n",
    "        subset = labels[labels['file'] == file]\n",
    "\n",
    "        matched_label = None\n",
    "        for _, lab in subset.iterrows():\n",
    "            lab_text = str(lab['text'])\n",
    "            # Check substring both ways for robustness\n",
    "            if lab_text in text or text in lab_text:\n",
    "                matched_label = lab['label']\n",
    "                break\n",
    "\n",
    "        matched_labels.append(matched_label if matched_label else 'other')\n",
    "\n",
    "    train['label'] = matched_labels\n",
    "    return train\n",
    "\n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    df['width'] = df.groupby(['file'])['x_max'].transform(\"max\")\n",
    "    df['heigh'] = df.groupby(['file'])['y_max'].transform(\"max\")\n",
    "    df['file_aspect_ratio'] = df.apply(lambda x: x['width'] / (x['heigh'] + 0.00001), axis=1)\n",
    "    # df['n_tokens'] = df.groupby('file')['text'].transform('count')\n",
    "\n",
    "    df['x_max'] = (df['x_max'] / df['width']).round(2)\n",
    "    df['y_max'] = (df['y_max'] / df['heigh']).round(2)\n",
    "    df['x_min'] = (df['x_min'] / df['width']).round(2)\n",
    "    df['y_min'] = (df['y_min'] / df['heigh']).round(2)\n",
    "    df['token_width'] = df['x_max'] - df['x_min']\n",
    "    df['token_heigh'] = df['y_max'] - df['y_min']\n",
    "    df['avg_font'] = df.groupby('file')['token_heigh'].transform(\"mean\")\n",
    "    df['font_size'] = df['token_heigh'] / df['avg_font']\n",
    "    df['aspect_ratio'] = df.apply(lambda x: x['token_width'] / (x['token_heigh'] + 0.00001), axis=1)\n",
    "    df['y_center'] = (df['y_max'] + df['y_min']) / 2\n",
    "    df['x_center'] = (df['x_max'] + df['x_min']) / 2\n",
    "    df['x_center_file'] = df.groupby(['file'])['x_center'].transform(\"mean\").round(2)\n",
    "    df['y_center_file'] = df.groupby(['file'])['y_center'].transform(\"mean\").round(2)\n",
    "    df['row'] = df['y_center'].round(2)\n",
    "    df['col'] = df['x_center'].round(1)\n",
    "    df['row_rank'] = df.groupby('file')['row'].rank(method='dense', ascending=True)\n",
    "    df['col_rank'] = df.groupby('file')['col'].rank(method='dense', ascending=True)\n",
    "    df['tokens_in_col'] = df.groupby(['file', 'col'])['text'].transform('count')\n",
    "    df['tokens_in_row'] = df.groupby(['file', 'row'])['text'].transform('count') \n",
    "    df['rows_in_col'] = df.groupby(['file', 'col'])['row_rank'].transform('max')\n",
    "    df['cols_in_row'] = df.groupby(['file', 'row'])['col_rank'].transform('max') \n",
    "    df['has_total_keyword'] = df['text'].apply(lambda t: bool(pattern.search(t)))\n",
    "    df['has_total_keyword_in_row'] = df.groupby(['file', 'row'])['has_total_keyword'].transform(\"max\")\n",
    "\n",
    "    totals = df[df['has_total_keyword']][['file', 'row']]\n",
    "    df = df.merge(totals, on=['file'], how='left', suffixes=('', '_total'))\n",
    "    df['row_dist_from_total']= np.abs(df['row'] - df['row_total'])\n",
    "    df = df.sort_values(['file', 'text', 'x_center', 'y_center', 'row_dist_from_total']).groupby(['file', 'text', 'x_center', 'y_center'], as_index=False).first()\n",
    "    df = df.drop('row_total', axis=1)\n",
    "\n",
    "    df = df.sort_values(['file', 'row'])\n",
    "    df['has_total_below'] = (\n",
    "        df.groupby('file')['has_total_keyword']\n",
    "        .transform(lambda x: x.iloc[::-1].cummax().iloc[::-1])\n",
    "    )\n",
    "    df['has_total_below'] = df.groupby('file')['has_total_below'].shift(-1).fillna(False)\n",
    "\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(x))\n",
    "    df['is_digit'] = df['text'].apply(match_price)\n",
    "    df['value'] = df['text'].apply(extract_price)\n",
    "\n",
    "    df['contains_date'] = df['text'].apply(lambda x: bool(date_pattern.search(x)))\n",
    "    df['tokens'] = df.groupby(['file', 'row'])['text'].transform(''.join)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "\n",
    "    # df['section'] = pd.cut(df['x_center'], bins=[0.0, 0.25, 0.5, 0.75, 1.0], labels=[1, 2, 3, 4], include_lowest=True)\n",
    "    # df['section_rank'] = df.groupby('file')['section'].rank(method='dense', ascending=True)\n",
    "    # df['section'] = LabelEncoder().fit_transform(df['section'])\n",
    "    # df['tokens_in_section'] = df.groupby(['file', 'section'])['text'].transform('count') \n",
    "    # df['top'] = df['row'] < 0.5\n",
    "    # df['bottom'] = df['row'] >= 0.5\n",
    "    # df['left'] = df['col'] < 0.5\n",
    "    # df['right'] = df['col'] >= 0.5\n",
    "    # df['tokens_top'] = df.groupby(['file'])['top'].transform('sum')\n",
    "    # df['tokens_bottom'] = df.groupby(['file'])['bottom'].transform('sum')\n",
    "    # df['tokens_left'] = df.groupby(['file'])['left'].transform('sum')\n",
    "    # df['tokens_right'] = df.groupby(['file'])['right'].transform('sum')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fix_total_label(df, threshold=0.015):\n",
    "    # word total in a row with total label by least diff\n",
    "    total_keywords = df.copy()\n",
    "    totals = df.copy()\n",
    "    total_keywords = total_keywords[total_keywords['has_total_keyword']][['file', 'text', 'has_total_keyword', 'y_center', 'y_max']]\n",
    "    total_keywords['label'] = 'total'\n",
    "    totals = totals[totals['label']=='total']\n",
    "\n",
    "    totals = totals.merge(total_keywords, on=['file'], suffixes=['', '_total'])\n",
    "    totals['diff_wtotal'] = totals['y_center'] - totals['y_center_total']\n",
    "    totals = totals.loc[lambda x: x['diff_wtotal'].abs() <= threshold]\n",
    "\n",
    "    totals = totals.sort_values(['file', 'label', 'y_min'], ascending=[True, True, False])\n",
    "    totals = totals.groupby(['file', 'label'], as_index=False).first()\n",
    "    totals = totals[['file', 'text', 'x_min', 'y_min', 'x_max', 'y_max', 'label']]\n",
    "\n",
    "    df = df.merge(totals, on=['file', 'text', 'x_min', 'y_min', 'x_max', 'y_max',], how='left', suffixes=('', '_true'))\n",
    "    df['label_true'] = df['label_true'].fillna('other')\n",
    "    df.loc[lambda x: x['label'] == 'total', 'label'] = df.loc[lambda x: x['label'] == 'total', 'label_true']\n",
    "    df['label'] = df['label'].apply(lambda x: 1 if x == 'total' else 0)\n",
    "    \n",
    "    # ad-hoc fix for own data input\n",
    "    df.loc[lambda x: (x['file'] == '5807493927290997517')\n",
    "           & (x['text'] == '\"4,58\"')\n",
    "           & (x['y_center'] >= 0.330 ), \"label\"\n",
    "           ] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_labels(df, image_source=\"/home/gleb_siz/ml_training/data/SROIE2019/train/img\"):\n",
    "    file = f\"{image_source}/{df['file'].iloc[0]}.jpg\"\n",
    "    img = cv2.imread(file)\n",
    "    for i, row in df.iterrows():\n",
    "        x1, y1, x2, y2 = row.x1, row.y1, row.x3, row.y3\n",
    "        if row.label ==1:\n",
    "            color = (255, 0, 0)\n",
    "        else:\n",
    "            color = (0, 255, 0)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "    img = cv2.resize(img, (800, 1000))\n",
    "    cv2.imshow(\"OCR Tokens\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18084800",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_df = load_ocr(TRAIN_FOLDER)\n",
    "img_df = load_img_data(TRAIN_FOLDER)\n",
    "labels_df = load_entity_data(TRAIN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83209629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN DATA\n",
    "df = ocr_df.copy()\n",
    "train_df = match_labels(df, labels_df)\n",
    "train_df = add_features(train_df)\n",
    "features_df = fix_total_label(train_df)\n",
    "with_total_files = features_df.loc[lambda x: x['label'] == 1]['file'].unique()\n",
    "features_df = features_df[features_df['file'].isin(with_total_files)]\n",
    "y = features_df['label']\n",
    "X = features_df[FEATURES]\n",
    "\n",
    "# TEST DATA\n",
    "test_ocr_df = load_ocr(TEST_FOLDER)\n",
    "test_img_df = load_img_data(TEST_FOLDER)\n",
    "test_labels_df = load_entity_data(TEST_FOLDER)\n",
    "\n",
    "df = test_ocr_df.copy()\n",
    "test_df = match_labels(df, test_labels_df)\n",
    "test_df = add_features(test_df)\n",
    "test_features_df = fix_total_label(test_df)\n",
    "with_total_files = test_features_df.loc[lambda x: x['label'] == 1]['file'].unique()\n",
    "test_features_df = test_features_df[test_features_df['file'].isin(with_total_files)]\n",
    "y_test = test_features_df['label']\n",
    "X_test = test_features_df[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "test_output = X_test\n",
    "test_output['label'] = y_pred\n",
    "test_output['text'] = test_df['text']\n",
    "test_output['file'] = test_df['file']\n",
    "test_output[['neg', 'pos']] = y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1eab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.loc[lambda x: ~x['file'].isin(with_total_files), :].sort_values(['file', 'pos'], ascending=[True, False]).groupby('file', as_index=False).first()[\n",
    "    ['file', 'text', 'label', 'pos']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================\n",
    "# # 6️⃣ Train XGBoost\n",
    "# # ==============================================\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y)\n",
    "y_test = le.fit_transform(y_test)\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight( 'balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, weights))\n",
    "\n",
    "# Assign weight to each sample\n",
    "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    # objective=\"multi:softmax\",\n",
    "    objective=\"binary:logistic\",\n",
    "    # scale_pos_weight=300,\n",
    "    # num_class=len(le.classes_),\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    # reg_alpha=0.1,\n",
    "    # min_child_weight=2,\n",
    "    use_label_encoder=False,\n",
    "    # eval_metric=\"mlogloss\",\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "_, X_val, _, y_val = train_test_split(\n",
    "    X_test, y_test, test_size=0.2, stratify=y_test, random_state=42\n",
    ")\n",
    "model.fit(X, \n",
    "          y_train, \n",
    "           eval_set=[(X_val, y_val),\n",
    "                    ],\n",
    "          sample_weight=sample_weights,\n",
    "          verbose=5\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff96989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from datetime import datetime \n",
    "best = \"~/ml_training/model/best.ubj\"\n",
    "datestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "archive = \"~/ml_training/model/archive/best_{datestamp}.ubj\"\n",
    "model.save_model(best)\n",
    "model.save_model(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================\n",
    "# # 7️⃣ Evaluate\n",
    "# # ==============================================\n",
    "\n",
    "model.load_model(best)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred_proba = model.predict_proba(X_test)  # shape: (n_samples, n_classes)\n",
    "roc_auc = roc_auc_score(y_test, y_pred, \n",
    "                        # multi_class='ovr'\n",
    "                        )  # or 'ovo'\n",
    "print(\"ROC-AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bebdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot\n",
    "xgb.plot_importance(model, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57818f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful layout graphs\n",
    "import matplotlib.pyplot as plt\n",
    "df = features_df[features_df['label'] == 1]\n",
    "plt.scatter(df['x_min'], df['y_min'], c=df['label'].astype('category').cat.codes)\n",
    "plt.gca().invert_yaxis()  # receipts have origin at top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data testing\n",
    "from paddleocr import PaddleOCR\n",
    "from paddlex.inference.pipelines.ocr.result import OCRResult\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# custom preprocessing\n",
    "ocr = PaddleOCR(\n",
    "    lang=\"pl\",\n",
    "    use_doc_orientation_classify=True, \n",
    "    use_doc_unwarping=False, \n",
    "    use_textline_orientation=False) # supports many langs\n",
    "outputs = pd.DataFrame()\n",
    "path = '/home/gleb_siz/ml_training/data/validation/img'\n",
    "files = os.listdir(path)\n",
    "for file in files:\n",
    "    results = ocr.predict(f\"{path}/{file}\")\n",
    "    df = pd.DataFrame(results[0]['rec_boxes'], columns=['x_min', 'y_min', 'x_max', 'y_max'])\n",
    "    df['file'] = file\n",
    "    df['text'] = results[0]['rec_texts']\n",
    "    df['score'] = results[0]['rec_scores']\n",
    "    df[df['score']>0.50].sort_values('text')\n",
    "    df = df[['x_min', 'y_min', 'x_max', 'y_max', 'text', 'file']]\n",
    "    for col in ['x_min', 'y_min', 'x_max', 'y_max',]:\n",
    "        df[col] = df[col].astype(int)\n",
    "    outputs = pd.concat([outputs, df])\n",
    "outputs = outputs.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a81755",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_df = outputs.copy()\n",
    "X_sample = add_features(outputs_df)\n",
    "# X_sample = X_sample[X_sample['is_digit']]\n",
    "y_sample = model.predict(X_sample[FEATURES])\n",
    "probabilities = model.predict_proba(X_sample[FEATURES])\n",
    "X_sample['pred'] = y_sample\n",
    "X_sample = pd.concat([X_sample, pd.DataFrame(probabilities, columns=[\"neg\", \"pos\"])], axis = 1)\n",
    "X_sample.sort_values(['file', 'pos'], ascending=[True, False]).groupby('file', as_index=False).first()[['file', 'text', 'value', 'pred', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d306e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file\ttext\tvalue\tpred\tpos\n",
    "# 0\t5807493927290997513.jpg\t9,99\t9.99\t0\t0.045834\n",
    "# 1\t5807493927290997514.jpg\t45,97\t45.97\t1\t0.999933\n",
    "# 2\t5807493927290997515.jpg\t118,50\t118.50\t1\t0.997495\n",
    "# 3\t5807493927290997516.jpg\t8,29\t8.29\t1\t0.985464\n",
    "# 4\t5807493927290997517.jpg\t4,58\t4.58\t0\t0.103868\n",
    "# 5\t5807493927290997518.jpg\tPLN 49,98\t49.98\t1\t0.998811\n",
    "# 6\t5807493927290997519.jpg\t49,98\t49.98\t0\t0.314266\n",
    "# 7\t5807493927290997524.jpg\t24,96\t24.96\t1\t0.801430\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis useful for feature actuall contribution into output, \n",
    "# more robust feature importance\n",
    "import shap\n",
    "\n",
    "# assume model and X are your trained model and feature DataFrame\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_sample[FEATURES])\n",
    "shap.summary_plot(shap_values, X_sample[FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcad5f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gleb_siz/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gleb_siz/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gleb_siz/.paddlex/official_models/latin_PP-OCRv5_mobile_rec`.\u001b[0m\n",
      "/tmp/ipykernel_617558/2119191960.py:156: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['has_total_below'] = df.groupby('file')['has_total_below'].shift(-1).fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5807493927290997513.jpg</td>\n",
       "      <td>9,99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5807493927290997514.jpg</td>\n",
       "      <td>25,98</td>\n",
       "      <td>25.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5807493927290997514.jpg</td>\n",
       "      <td>45,97</td>\n",
       "      <td>45.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5807493927290997515.jpg</td>\n",
       "      <td>118,50</td>\n",
       "      <td>118.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5807493927290997516.jpg</td>\n",
       "      <td>4,99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>5807493927290997516.jpg</td>\n",
       "      <td>8,29</td>\n",
       "      <td>8.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5807493927290997517.jpg</td>\n",
       "      <td>4,58</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>5807493927290997518.jpg</td>\n",
       "      <td>PLN 49,98</td>\n",
       "      <td>49.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5807493927290997519.jpg</td>\n",
       "      <td>49,98</td>\n",
       "      <td>49.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>5807493927290997524.jpg</td>\n",
       "      <td>24,96</td>\n",
       "      <td>24.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>receipt.jpg</td>\n",
       "      <td>200,67</td>\n",
       "      <td>200.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file       text   value\n",
       "18   5807493927290997513.jpg       9,99    9.99\n",
       "75   5807493927290997514.jpg      25,98   25.98\n",
       "83   5807493927290997514.jpg      45,97   45.97\n",
       "136  5807493927290997515.jpg     118,50  118.50\n",
       "163  5807493927290997516.jpg       4,99    4.99\n",
       "172  5807493927290997516.jpg       8,29    8.29\n",
       "199  5807493927290997517.jpg       4,58    4.58\n",
       "265  5807493927290997518.jpg  PLN 49,98   49.98\n",
       "300  5807493927290997519.jpg      49,98   49.98\n",
       "344  5807493927290997524.jpg      24,96   24.96\n",
       "516              receipt.jpg     200,67  200.67"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E2E run\n",
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from paddleocr import PaddleOCR\n",
    "from paddlex.inference.pipelines.ocr.result import OCRResult\n",
    "import cv2\n",
    "from PIL import Image\n",
    "path = '/home/gleb_siz/ml_training/data/validation/img'\n",
    "model_path = '/home/gleb_siz/ml_training/model/best.ubj'\n",
    "# custom preprocessing\n",
    "ocr = PaddleOCR(\n",
    "    lang=\"pl\",\n",
    "    use_doc_orientation_classify=True, \n",
    "    use_doc_unwarping=False, \n",
    "    use_textline_orientation=False) # supports many langs\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model(model_path)\n",
    "outputs = pd.DataFrame()\n",
    "\n",
    "files = os.listdir(path)\n",
    "for file in files:\n",
    "    results = ocr.predict(f\"{path}/{file}\")\n",
    "    df = pd.DataFrame(results[0]['rec_boxes'], columns=['x_min', 'y_min', 'x_max', 'y_max'])\n",
    "    df['file'] = file\n",
    "    df['text'] = results[0]['rec_texts']\n",
    "    df['score'] = results[0]['rec_scores']\n",
    "    df[df['score']>0.50].sort_values('text')\n",
    "    df = df[['x_min', 'y_min', 'x_max', 'y_max', 'text', 'file']]\n",
    "    for col in ['x_min', 'y_min', 'x_max', 'y_max',]:\n",
    "        df[col] = df[col].astype(int)\n",
    "    outputs = pd.concat([outputs, df])\n",
    "outputs = outputs.reset_index()\n",
    "outputs_df = outputs\n",
    "X_sample = add_features(outputs_df)\n",
    "y_sample = model.predict(X_sample[FEATURES])\n",
    "X_sample['pred'] = y_sample\n",
    "X_sample[X_sample['pred']==1][['file', 'text', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958bca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_617558/2119191960.py:156: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['has_total_below'] = df.groupby('file')['has_total_below'].shift(-1).fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5807493927290997513.jpg</td>\n",
       "      <td>9,99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5807493927290997514.jpg</td>\n",
       "      <td>19,99</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5807493927290997514.jpg</td>\n",
       "      <td>25,98</td>\n",
       "      <td>25.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5807493927290997514.jpg</td>\n",
       "      <td>5,66</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5807493927290997514.jpg</td>\n",
       "      <td>45,97</td>\n",
       "      <td>45.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5807493927290997515.jpg</td>\n",
       "      <td>118,50</td>\n",
       "      <td>118.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5807493927290997516.jpg</td>\n",
       "      <td>4,99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>5807493927290997516.jpg</td>\n",
       "      <td>8,29</td>\n",
       "      <td>8.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5807493927290997517.jpg</td>\n",
       "      <td>4,58</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>5807493927290997518.jpg</td>\n",
       "      <td>PLN 49,98</td>\n",
       "      <td>49.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5807493927290997519.jpg</td>\n",
       "      <td>49,98</td>\n",
       "      <td>49.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>5807493927290997524.jpg</td>\n",
       "      <td>24,96</td>\n",
       "      <td>24.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>receipt.jpg</td>\n",
       "      <td>200,67</td>\n",
       "      <td>200.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file       text   value\n",
       "18   5807493927290997513.jpg       9,99    9.99\n",
       "73   5807493927290997514.jpg      19,99   19.99\n",
       "75   5807493927290997514.jpg      25,98   25.98\n",
       "81   5807493927290997514.jpg       5,66    5.66\n",
       "83   5807493927290997514.jpg      45,97   45.97\n",
       "136  5807493927290997515.jpg     118,50  118.50\n",
       "163  5807493927290997516.jpg       4,99    4.99\n",
       "172  5807493927290997516.jpg       8,29    8.29\n",
       "199  5807493927290997517.jpg       4,58    4.58\n",
       "265  5807493927290997518.jpg  PLN 49,98   49.98\n",
       "300  5807493927290997519.jpg      49,98   49.98\n",
       "344  5807493927290997524.jpg      24,96   24.96\n",
       "516              receipt.jpg     200,67  200.67"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample = add_features(outputs_df)\n",
    "y_sample = model.predict(X_sample[FEATURES])\n",
    "X_sample['pred'] = y_sample\n",
    "X_sample[X_sample['pred']==1][['file', 'text', 'value']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
